Cryptography is involved in many parts of our daily life, e.g. credit cards, Internet banking, electronic voting etc. The Oxford Dictionary of English proposes a simple, yet incomplete, definition of cryptology as \quotes{the study of codes, or the art of writing and solving them}. The roots of this definition are to be found in History: the invention of cryptology comes from the problem of secret communications of diplomatic and military information. The basic idea is to apply a \quotes{complicated} transformation to the information to be protected. On one side of cryptology, users utilize secret codes, while on the other side, adversaries attempt to break through the secrecy of the messages to recover the hidden information. One of the oldest and simplest cryptologic technique, Caesar's Cipher, consists of replacing each letter of message by the letter three positions down the alphabet (looping back at the end).

Until the XIXth century, the study of secret codes lacked a precise and consistent theory, and designing or breaking such codes was considered as an art. The construction of \quotes{good codes} or deciphering relied on time, patience and ingenuity. With the introduction of mathematical formalism, the study of secret codes became a science that is commonly known as cryptology. This science contains two aspects: cryptography and cryptanalysis. Cryptography aims at designing new methods to ensure the secrecy of communications, and cryptanalysis aims at discovering flaws in these methods. And even though it was typical back then to keep these methods secret to make cryptanalysis more complicated, such a secrecy \quotes{by obscurity} is recognized to be delusive.


In this age of digital information and telecommunications, cryptography is now far from being restricted to the military and diplomatic fields. It has became a cornerstone in our daily life. Cryptography is present in our cellphones, our banking cards, our biometric passports, our Internet browsers, and many (often unsuspected) other products, which all require to guarantee security properties on their communications and on their data. Moreover, beyond the confidentiality of the secret information, one should also ensure that these contacts are secure against eavesdropping or injection of illegitimate messages. Thus, the scope of cryptography now includes among other things data integrity that is the fact that the data has not been modified, and data authenticity that is the fact that the sender is legitimate. Therefore, the cryptographer aims at designing systems that ensure these security properties, while the cryptanalyst looks at possible flaws that would reveal that these properties are actually not verified.


In their groundbreaking paper \textit{New directions in Cryptography} \cite{1055638} published in 1976, W. Diffie and M. Hellman introduced the concept of public-key cryptography and bridged cryptography to complexity theory. Until then, all the cryptographic systems were relying on a common secret shared between the sender and the receiver, or were using a symmetric secret key (symmetric because it was the same for both parties). Typical example of a symmetric encryption scheme is a block cipher. Such a cryptosystem is a pair of families $\{E_k\}_{k \in K}$ and $\{D_k\}_{k \in K}$ of algorithms representing invertible transformations over blocks of fixed length (e.g. $128$ bits), inverse of each other, indexed by a symmetric key $k \in K$. When the sender conventionally named Alice, who is sharing a common secret key $k$ with the receiver also conventionally named Bob, wants to confidentially send a message $m$ to Bob, she can send the ciphertext $c = E_k(m)$ from which Bob can recover $m$ by decrypting $c$, $m = D_k(c)$. Block ciphers remain fundamental and very useful ingredient of today's cryptography; they are extensively used in nearly all systems that are using cryptography.


All symmetric key cryptography (also called secret key cryptography) assumes that the two parties exchanging secret messages share a common secret key. Unfortunately, the secure distribution of such a key is a major issue. The methods of exchanging a secret key through a possibly eavesdropped conversation without sharing any secret beforehand is the fundamental of key-exchange protocols. In details, the key-exchange problem is how to exchange whatever keys or other information are needed so that no one else can obtain a copy. Historically, this required trusted couriers, diplomatic bags, or some other secure channel. So if the attacker is able to passively capture data and later gets an access to the private key, then the attacker could decode all previously captured data. In \cite{1055638}, W. Diffie and M. Hellman proposed an algorithm which revolutionized the concept of key-exchange, in which eliminates the need for a secure key distribution channel by constructing a procedure that enables two parties to derive a shared key over unsecured channel without actually transmitting the shared key itself. Indeed, sending the key in advance over a secure channel would be unrealistic for today's applications. The key-exchange mechanism is an efficient solution to the problem of creating a common secret between two participants, which it can subsequently be used to encrypt all the communications thanks to the symmetric cipher. Moreover, it is one-round which implies that each participant is allowed to talk once and broadcast some data to the other participant. The two main approaches for Diffie-Helman protocol uses either finite field or elliptic curve but they both are not safe under quantum computers due to Shor's quantum algorithm \cite{Shor:1997:PAP:264393.264406}.

In recent years, lattice-based cryptography has been recognized for its many attractive properties, such as strong provable security guarantees and apparent resistance to quantum attacks, flexibility for realizing powerful tools like fully homomorphic encryption and high asymptotic efficiency. Indeed, several works have demonstrated that for basic tasks like encryption and authentication, lattice-based primitives can have performance competitive with or even surpassing those based on classical mechanisms like RSA or Diffie-Hellman. However, there still has been relatively little work done on developing lattice based key-exchange for deployment in real-world cryptosystems and protocols.

Many lattice based cryptography algorithm are based on the Learning With Errors problem ($\mathrm{LWE}$) which is a variant of lattice problems that is as hard to solve as several worst-case lattice problems. The basics of Ring-$\mathrm{LWE}$ (ring variant of $\mathrm{LWE}$) based key-exchange protocol was introduced for the first time by Regev in \cite{Regev:2005:LLE:1060590.1060603} and later the key-agreement algorithm improved by Ding in \cite{ding2012simple}. Ding's reconciliation or key-agreement method was original as it introduced the concept of sending extra information to improve the success probability of key-agreement. Thereafter, Peikert in \cite{peikert2014lattice} addressed the shortcomings of Ding's method and provided a relatively simpler reconciliation algorithm.

$\mathrm{BCNS}$ protocol \cite{bos2015post}, which is sponsored by Microsoft Research, does not introduce a new key-agreement algorithm but it provides parameters. It uses Peikert's key-agreement algorithm which is a derivative of Ding's method and also it is the first optimized $\mathrm{C}$ implementation of Ring-$\mathrm{LWE}$ based key-exchange. Most importantly, this protocol provided a drop-in replacement (or patch) for the Transport Layer Security ($\mathrm{TLS}$) protocol. In further revisions of Open-$\mathrm{SSL}$, the $\mathrm{BCNS}$ protocol is included by default in Open-SSL. This enables users to seamlessly switch to quantum-safe protocol. $\mathrm{BCNS}$ protocol goes further and proves that cost of switching from non-quantum-safe key-exchange to quantum-safe is not too high. Thus, post-quantum key-exchange can already be considered practical.

$\mathrm{NewHope}$ protocol \cite{alkim2015post}, which is implemented in collaboration with Google, does introduce a new key-agreement algorithm which is a derivative of Peikert's method and also provides improved parameters. The new key-agreement algorithm is a generalization of Peikert's algorithm in $4$-dimension instead of $1$-dimension that Peikert suggested. $\mathrm{NewHope}$ protocol provides a more practical approach in addition to a more optimized $\mathrm{C}$ reference code. $\mathrm{NewHope}$ protocol later was added to Google's fork of Open-SSL also known as Boring-SSL and adjusted to use it's built-in functions and subsequently it is currently being used by Google and included in Google Chrome web browser. Further, the $\mathrm{AVX2}$ assembly language implementation of this protocol outperforms state-of-the art elliptic curve cryptography based Diffie-Hellman key-exchange, $\mathrm{X25519}$, thus showing that using quantum safe key-exchange is not only a viable option but also a faster one.

In this work we do a detailed analysis of Ring-$\mathrm{LWE}$ based key-exchange reconciliation (or key agreement) methods, protocols, parameter choices, noise sampling algorithms, performance and compare two implementation of Ring-$\mathrm{LWE}$ based key-exchange protocols: $\mathrm{BCNS}$ and $\mathrm{NewHope}$. Throughout this thesis, we study the relation between lattices and lattice based key-exchange and how lattice based cryptography evolved overtime starting from Ajtai's result up-to highly optimized $\mathrm{NewHope}$ key-exchange protocol.  

This paper is organized as follows: chapter 2 discusses preliminary subjects needed to understand importance of lattices and how Ring-$\mathrm{LWE}$ based key-exchange tries to replace existing key-exchange protocols. More specifically, this chapter discusses Diffie-Hellman, Shor's algorithms and how it breaks Diffie-Hellman by solving discrete logarithm problem efficiently. Thereafter, chapter 3 overviews definition of lattice, lattice properties, lattice reduction and most importantly lattice problems. Chapter 4 is the main part of this thesis that overviews basics of Ring-$\mathrm{LWE}$ key-exchange, the need for reconciliation and analysis of different key-agreement (or reconciliation) methods and describes $\mathrm{BCNS}$ and $\mathrm{NewHope}$ protocols in details. Chapter 5 describes implementation specifics of $\mathrm{BCNS}$ and $\mathrm{NewHope}$ protocols. For example, error sampling algorithm and performance analysis. Chapter 6 discusses future works and conclusion or the main take away from this thesis.

In appendix chapter, we overview early lattice based public-key cryptosystem that was broken using lattice reduction. Further, it discusses basic implementation of all Ring-$\mathrm{LWE}$ based key-exchange protocols using SageMath (extension of Python programming language). 